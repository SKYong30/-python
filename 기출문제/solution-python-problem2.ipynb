{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-09T05:29:35.554842Z","iopub.execute_input":"2022-03-09T05:29:35.555228Z","iopub.status.idle":"2022-03-09T05:29:35.595585Z","shell.execute_reply.started":"2022-03-09T05:29:35.555096Z","shell.execute_reply":"2022-03-09T05:29:35.594889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 문제는 https://didalsgur.tistory.com/entry/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EC%A0%84%EB%AC%B8%EA%B0%80-ADP-20%ED%9A%8C-%EC%8B%A4%EA%B8%B0%EC%8B%9C%ED%97%98-%ED%9B%84%EA%B8%B0\n# 참고했습니다\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:29:41.758038Z","iopub.execute_input":"2022-03-09T05:29:41.758379Z","iopub.status.idle":"2022-03-09T05:29:41.763375Z","shell.execute_reply.started":"2022-03-09T05:29:41.758344Z","shell.execute_reply":"2022-03-09T05:29:41.762182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1번\n날씨 온도 예측, 종속변수 :actual(최고온도)   \n데이터 출처 : https://towardsdatascience.com/random-forest-in-python-24d0893d51c0     \n데이터 경로 : /kaggle/input/adp-kr-p2/problem1.csv    \ntemp_1 : 전날 최고온도    \ntemp_2 : 전전날 최고온도    \nfriend : 친구의 예측온도     \n\n","metadata":{}},{"cell_type":"markdown","source":"### 1-1 데이터 확인 및 전처리\n- 데이터 EDA 수행     \n- 결측치를 확인하고 처리 방안에 대해 논의하라  \n- 데이터 분할 방법 설명     \n- 최종 데이터셋이 적절함을 주장하라     ","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport seaborn as sns\ndf =pd.read_csv('/kaggle/input/adp-kr-p2/problem1.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:29:42.458148Z","iopub.execute_input":"2022-03-09T05:29:42.458494Z","iopub.status.idle":"2022-03-09T05:29:43.689486Z","shell.execute_reply.started":"2022-03-09T05:29:42.458453Z","shell.execute_reply":"2022-03-09T05:29:43.688449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:29:43.691743Z","iopub.execute_input":"2022-03-09T05:29:43.692091Z","iopub.status.idle":"2022-03-09T05:29:43.718037Z","shell.execute_reply.started":"2022-03-09T05:29:43.692046Z","shell.execute_reply":"2022-03-09T05:29:43.717314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:29:43.719435Z","iopub.execute_input":"2022-03-09T05:29:43.719886Z","iopub.status.idle":"2022-03-09T05:29:43.725209Z","shell.execute_reply.started":"2022-03-09T05:29:43.719854Z","shell.execute_reply":"2022-03-09T05:29:43.724195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(df)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:29:43.727495Z","iopub.execute_input":"2022-03-09T05:29:43.728303Z","iopub.status.idle":"2022-03-09T05:30:11.274959Z","shell.execute_reply.started":"2022-03-09T05:29:43.728247Z","shell.execute_reply":"2022-03-09T05:30:11.274052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:11.276436Z","iopub.execute_input":"2022-03-09T05:30:11.276857Z","iopub.status.idle":"2022-03-09T05:30:11.294275Z","shell.execute_reply.started":"2022-03-09T05:30:11.276821Z","shell.execute_reply":"2022-03-09T05:30:11.293567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:11.296175Z","iopub.execute_input":"2022-03-09T05:30:11.296597Z","iopub.status.idle":"2022-03-09T05:30:11.351388Z","shell.execute_reply.started":"2022-03-09T05:30:11.296556Z","shell.execute_reply":"2022-03-09T05:30:11.350403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:11.353021Z","iopub.execute_input":"2022-03-09T05:30:11.353326Z","iopub.status.idle":"2022-03-09T05:30:11.363729Z","shell.execute_reply.started":"2022-03-09T05:30:11.353293Z","shell.execute_reply":"2022-03-09T05:30:11.362864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['date'] =df['year'].astype('str')+'-'+df['month'].astype('str')+'-'+df['day'].astype('str')\ndf['date'] = pd.to_datetime(df['date'])","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:11.365084Z","iopub.execute_input":"2022-03-09T05:30:11.365598Z","iopub.status.idle":"2022-03-09T05:30:11.386288Z","shell.execute_reply.started":"2022-03-09T05:30:11.36556Z","shell.execute_reply":"2022-03-09T05:30:11.384973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"v = pd.DataFrame(pd.date_range(start=df['date'].dt.strftime('%Y-%m-%d').min(), end=df['date'].dt.strftime('%Y-%m-%d').max()))[0].dt.strftime('%Y-%m-%d').values","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:11.387819Z","iopub.execute_input":"2022-03-09T05:30:11.38867Z","iopub.status.idle":"2022-03-09T05:30:11.412983Z","shell.execute_reply.started":"2022-03-09T05:30:11.388627Z","shell.execute_reply":"2022-03-09T05:30:11.412222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=set(v) - set(df['date'].dt.strftime('%Y-%m-%d'))\nprint(a)\nlen(a)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:11.414594Z","iopub.execute_input":"2022-03-09T05:30:11.41522Z","iopub.status.idle":"2022-03-09T05:30:11.433397Z","shell.execute_reply.started":"2022-03-09T05:30:11.415178Z","shell.execute_reply":"2022-03-09T05:30:11.432444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:11.436003Z","iopub.execute_input":"2022-03-09T05:30:11.436818Z","iopub.status.idle":"2022-03-09T05:30:11.462749Z","shell.execute_reply.started":"2022-03-09T05:30:11.436767Z","shell.execute_reply":"2022-03-09T05:30:11.461557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Answer \n데이터 상에서 수치 결측치는 존재하지 않는다. 시계열 데이터 관점으로 봤을때, 18일치의 일자 데이터가 결측치로 존재한다.     \n문제 해결시 시계열 방식으로 접근 하지 않을 것이기에 \n누락된 일자에 대해서 따로 결측치 처리를 해주지 않을 것이다.     \n시계열 관점으로 해석을 할 경우 누락된 데이터는 평균 보간을 실시 하여 처리할 수 있다.    \n    \n데이터 시각화 결과 상관관계를 보이는 컬럼들이 확인되며 주기적 경향을 보이는 데이터들이 확인된다.     \n\nyear, month, day, week, 값은 불필요 컬럼으로 제외한다. week의 경우 원핫인코딩을 진행해서 추가한다.      \ntrain셋과 test셋은 8:2비율로 나눠서 모델링을 진행한다.     \nfriend 컬럼의 경우 상관관계를 확인했을때 상대적으로 낮은 값을 가지기에 제외하고 학습을 진행한다.     ","metadata":{}},{"cell_type":"code","source":"dfd = pd.get_dummies(df)\ndf_drop = dfd.drop(columns=['year','month','day','friend','date'])\n\nX = df_drop.drop(columns=['actual'])\ny = df_drop['actual']\n\nfrom sklearn.model_selection import train_test_split\n\nX_train,X_test , y_train,y_test = train_test_split(X,y,random_state=2,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:11.464403Z","iopub.execute_input":"2022-03-09T05:30:11.465162Z","iopub.status.idle":"2022-03-09T05:30:11.683489Z","shell.execute_reply.started":"2022-03-09T05:30:11.465085Z","shell.execute_reply":"2022-03-09T05:30:11.682534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-2 Random Forest 모델 적합 및 검증  \n- Random Forest 학습 및 예측 결과 해석    \n- 예측 결과 검정 해석, 중요변수 도출    \n- 변수 중요성 분석 및 그래프 출력     ","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nimport time\nimport matplotlib.pyplot as plt\n\nresult = []\nrf = RandomForestRegressor(random_state=22)\nstart = time.time()\nrf.fit(X_train,y_train)\nend = time.time()\n\npred = rf.predict(X_test)\nprint('RandomForest r2_score : ',r2_score(y_test,pred))\nprint('learning time ',end-start)\nimportances = rf.feature_importances_\nforest_importances = pd.Series(importances, index=X_train.columns)\n\nfig, ax = plt.subplots()\nforest_importances.plot.bar( ax=ax)\nax.set_title(\"Feature importances\")\nfig.tight_layout()\n\nprint('temp_1 ,average , forecast_acc 순으로 변수 중요도를 확인 할 수 있다')\n\nresult.append([end-start,r2_score(y_test,pred)])","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:24.991675Z","iopub.execute_input":"2022-03-09T05:30:24.991997Z","iopub.status.idle":"2022-03-09T05:30:25.552227Z","shell.execute_reply.started":"2022-03-09T05:30:24.991963Z","shell.execute_reply":"2022-03-09T05:30:25.551302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-3 SVM(Support Vector Machine) 모델 적합 및 검증 \n- svm 학습 및 예측 결과 해석    \n- 예측 결과 검정 해석, 중요변수 도출    \n- 변수 중요성 분석 및 그래프 출력     ","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVR\nfrom sklearn.metrics import r2_score\nimport time\nsvm = SVR()\n\nstart = time.time()\nsvm.fit(X_train,y_train)\nend = time.time()\n\npred = svm.predict(X_test)\nprint('svm r2_score : ',r2_score(y_test,pred))\nprint('learning time ',end-start)\nprint('svm은 변수 중요도를 따로 추출 할 수 없다. r2_score의 경우 RandomForest에 비해 낮다')\n\n\nresult.append([end-start,r2_score(y_test,pred)])","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:26.482414Z","iopub.execute_input":"2022-03-09T05:30:26.482703Z","iopub.status.idle":"2022-03-09T05:30:26.503674Z","shell.execute_reply.started":"2022-03-09T05:30:26.482673Z","shell.execute_reply":"2022-03-09T05:30:26.502872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1-4 모델 비교 및 향후 개선 방향 도출\n- Random Forest, SVM 모델의 결과 비교 후 최종 모델 선택    \n- 두 모델의 장단점 분석, 추후 운영 관점에서 어떤 모델을 선택할 것인가?    \n- 모델링 관련 추후 개선 방향 제시     ","metadata":{}},{"cell_type":"code","source":"result_df = pd.DataFrame(result,columns = ['learning time','r2_score'])\nresult_df.index = ['RandomForest','Svm']\ndisplay(result_df)\n\nprint('''\n파라미터 튜닝을 제외한 기본모델의 경우 모델학습시간은 랜덤포레스트가 svm에 비해 더 오래 걸린다.      \ntest셋에 대한 모델 r2score는 랜덤포레스트가 더 높다.    \n모델 학습시간을 중점둔다면 svm이 더 유리하다. 하지만 랜덤포레스트의 경우 변수중요도를 확인 할 수 있고, 정확도가 더 높기 때문에    \n최종적으로는 랜덤포레스트를 선택한다. \n''')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:28.07035Z","iopub.execute_input":"2022-03-09T05:30:28.070797Z","iopub.status.idle":"2022-03-09T05:30:28.084305Z","shell.execute_reply.started":"2022-03-09T05:30:28.070767Z","shell.execute_reply":"2022-03-09T05:30:28.083194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2번 \n5분간격의 가구별 전력 사용량의 데이터    \n데이터 출처 : 자체생성    \n데이터 경로 : /kaggle/input/adp-kr-p2/problem2.csv    ","metadata":{}},{"cell_type":"markdown","source":"### 2-1 데이터 전처리\n각 가구의 15분간격의 전력량의 합을 구하고 해당데이터를 바탕으로 총 5개의 군집으로 군집화를 진행한 후 아래의 그림과 같은 형태로 출력하라.    \n군집화를 위한 데이터 구성의 이유를 설명하라    \n(군집 방식에 따라 Cluster컬럼의 값은 달라질수 있음)\n![image](https://github.com/Datamanim/datarepo/blob/main/adp/p2/problem2.png?raw=true)","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nttt= pd.read_csv('/kaggle/input/adp-kr-p2/problem2.csv')\ntt = ttt.sort_values(['houseCode','date']).reset_index(drop=True)\n\ntt['date'] = pd.to_datetime(tt['date'])\n\ntg = tt.groupby(['houseCode']).resample('15min', on='date')['power consumption'].sum().reset_index()\n\ntg = tg.rename(columns= {'power consumption':'power consumption sum'})\n\ntgg = tg.copy()\n\ntgg['c'] =tgg['houseCode'].str[-2:].astype('int')\ntgg['d'] =tgg['date'].dt.hour\ntgg['e'] =tgg['date'].dt.day\n\nfrom sklearn.cluster import KMeans \n\n# k-means clustering 실행\nkmeans = KMeans(n_clusters=5)\nkmeans.fit(tgg.iloc[:,2:].values)\n\ntg['Cluster'] =kmeans.labels_\n\ntg","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:29.09128Z","iopub.execute_input":"2022-03-09T05:30:29.092048Z","iopub.status.idle":"2022-03-09T05:30:35.606462Z","shell.execute_reply.started":"2022-03-09T05:30:29.092008Z","shell.execute_reply":"2022-03-09T05:30:35.605783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2-2 히트맵\n2-1의 데이터를 바탕으로 각 군집의 요일, 15분간격별 전력사용량의 합을 구한 후 아래와 같이 시각화 하여라    \n(수치는 동일하지 않을 수 있음 2-1의 데이터가 정확하게 아래와 같은 이미지로 변환 됐는지 주로 확인)     \n![image](https://github.com/Datamanim/datarepo/blob/main/adp/p2/problem2_Example.png?raw=true)","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ntg['day'] = tg.date.dt.day_name()\n\ntg['min'] = tg.date.dt.strftime('%H:%M')\n\npv = tg.groupby(['Cluster','day','min'],as_index=False).sum()\nfor v in range(5):\n    plt.figure(figsize=(20,3))\n    target = pv.loc[pv.Cluster==v]\n    pvt = target.pivot(index='day',columns='min',values='power consumption sum').reindex(['Sunday','Saturday','Friday','Thursday','Wednesday','Tuesday','Monday'])\n    plt.pcolor(pvt)\n    plt.title('Cluster'+str(v))\n    plt.xticks(range(len(pvt.columns)),pvt.columns,rotation=90)\n    plt.yticks(np.arange(len(pvt.index))+0.5,pvt.index)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:35.608214Z","iopub.execute_input":"2022-03-09T05:30:35.608667Z","iopub.status.idle":"2022-03-09T05:30:42.887677Z","shell.execute_reply.started":"2022-03-09T05:30:35.608634Z","shell.execute_reply":"2022-03-09T05:30:42.886723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3번 태양광 데이터\n예측 변수 :SOLAR PV\n\n\n데이터 경로 : /kaggle/input/adp-kr-p2/problem3.csv    \n데이터 출처 : https://www.kaggle.com/cheedcheed/california-renewable-production-20102018","metadata":{}},{"cell_type":"markdown","source":"### 3-1\n**데이터셋 분할 및 결과 검증**    \n- 데이터셋 7:3 분할    \n- 데이터 전처리 및 예측 모델 생성    \n- 모델 성능 검증 : RMSE, R제곱, 정확도(아래 방식으로 연산)로 구하여라    \n- 정확도의 경우 실제값>예측값인 경우 (1-예측값/실제값), 실제값<예측값인 경우 (1- 실제값/예측값)으로 하고 이것들을 평균낸 후 1에서 뺀값으로 한다.   \n  분수식의 분모가 0인 경우의 정확도는 0.5로 취급한다.\n\n- 최종 결과 제출 : 소수점 3째자리 반올림     ","metadata":{}},{"cell_type":"code","source":"df= pd.read_csv('/kaggle/input/adp-kr-p2/problem3.csv')\n\ndf = df.drop(columns =['SOLAR'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:42.888949Z","iopub.execute_input":"2022-03-09T05:30:42.8892Z","iopub.status.idle":"2022-03-09T05:30:43.066025Z","shell.execute_reply.started":"2022-03-09T05:30:42.88917Z","shell.execute_reply":"2022-03-09T05:30:43.061715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score,accuracy_score, mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\n\n\ndef suntimeChecker(x):\n    if pd.to_datetime(x).hour in list(range(6,18)):\n        return 1\n    else:\n        return 0\n\ndf['TIMESTAMP'] = pd.to_datetime(df['TIMESTAMP'])\ndf['suntime'] = df['TIMESTAMP'].apply(suntimeChecker)\n\nX = df.drop(columns=['TIMESTAMP','Hour','SOLAR PV'])\ny= df['SOLAR PV']\n\nX_train,X_test ,y_train,y_test = train_test_split(X,y,random_state =2 , test_size =0.3)\n\nrf =RandomForestRegressor()\nrf.fit(X_train,y_train)\n\npred = rf.predict(X_test)\n\ndef getEachAccuracy(y_true,y_pred):\n    if y_true ==0:\n        return 0.5\n    if y_pred ==0:\n        return 0.5\n    \n    if y_true > y_pred:\n        return 1-(y_pred/y_true)\n    else:\n        return 1-(y_true/y_pred)\n    \nacc = []\nfor i,v in enumerate(y_test):\n    acc.append(getEachAccuracy(v,pred[i]))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:43.068267Z","iopub.execute_input":"2022-03-09T05:30:43.068845Z","iopub.status.idle":"2022-03-09T05:30:59.766419Z","shell.execute_reply.started":"2022-03-09T05:30:43.068804Z","shell.execute_reply":"2022-03-09T05:30:59.765257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 데이터 전처리의 경우 날짜 컬럼을 제외하고, nan값만 있는 컬럼을 제외했다. \n# 해가 존재하는시각을 (06~17시)로 설정해서 파생변수를 만들어줬다\n# 정확도의 경우 아래와 같다\n\nprint('RMSE',round(mean_squared_error(y_test, pred)**0.5,3))\nprint('r2',round(r2_score(y_test, pred),3))\nprint('acc',1- round(sum(acc)/len(acc),3))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T05:30:59.768525Z","iopub.execute_input":"2022-03-09T05:30:59.769139Z","iopub.status.idle":"2022-03-09T05:30:59.783679Z","shell.execute_reply.started":"2022-03-09T05:30:59.769083Z","shell.execute_reply":"2022-03-09T05:30:59.782446Z"},"trusted":true},"execution_count":null,"outputs":[]}]}